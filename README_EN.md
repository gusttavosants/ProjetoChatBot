RAG ChatBot â€” FastAPI + LangChain + ChromaDB + React

This project implements an intelligent chatbot using RAG (Retrieval Augmented Generation) to answer user questions based on information stored in a SQL database and vectorized documents in ChromaDB.

It consists of:

Backend (FastAPI) â€” RAG pipeline, embeddings, retrieval, SQL access, and REST API

Frontend (React) â€” simple chat interface

Testing (Pytest) â€” API tests

LLM (Google Gemini) â€” used for contextual response generation

ğŸ“‚ Project Structure
ProjetoChatBotComRAG/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py               # FastAPI server and endpoints
â”‚   â”œâ”€â”€ rag_pipeline.py      # RAG pipeline (embeddings, retrieval, LLM)
â”‚   â”œâ”€â”€ database/            # SQL database + scripts
â”‚   â”œâ”€â”€ chroma_db/           # Local ChromaDB storage
â”‚   â”œâ”€â”€ .env                 # Environment configuration
â”‚   â””â”€â”€ tests/               # Pytest test suite
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ src/
    â”œâ”€â”€ public/
    â””â”€â”€ package.json

ğŸš€ Tech Stack
Backend

FastAPI

LangChain

ChromaDB

Sentence Transformers

Google Gemini (google-genai)

Python-dotenv

Pydantic

Frontend

React + Vite

Axios

Testing

Pytest

Pytest-asyncio

HTTPX

âš™ï¸ Backend Setup
1ï¸âƒ£ Create and activate the virtual environment
cd backend
python -m venv venv
venv\Scripts\activate   # Windows

2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

3ï¸âƒ£ Create the .env file
GEMINI_API_KEY=YOUR_API_KEY
DB_PATH=./database/database.db
CHROMA_PATH=./chroma_db

4ï¸âƒ£ Start the server
uvicorn app:app --reload


API available at:
ğŸ‘‰ http://localhost:8000

ğŸ¤– RAG Pipeline Overview

The RAG pipeline implemented in rag_pipeline.py follows this flow:

Receive the question from the frontend

Query SQL database for relevant entries

Retrieve vector-based context from ChromaDB

Build a combined context-aware prompt

Send prompt to Google Gemini

Return final enriched response to the client

ğŸ§ª Running Tests

Run all tests with:

pytest -v


Tests include:

/chat endpoint

RAG pipeline logic

Basic integration tests

ğŸ–¥ï¸ Frontend Setup
cd frontend
npm install
npm run dev


Frontend runs on:
ğŸ‘‰ http://localhost:5173

ğŸŒ Full System Flow

User sends a question in the React UI

Backend receives and processes it via RAG

SQL database is queried first

ChromaDB retrieves vector embeddings

Gemini generates final answer

Response is returned to the UI

ğŸ“¡ Main Endpoint
POST /chat

Request:

{
  "question": "Tell me about the stored product data."
}


Response:
Natural language answer generated using retrieved SQL + vector context.

ğŸ“¦ Backend Dependencies
fastapi
uvicorn[standard]
python-dotenv
pydantic

google-genai

langchain
langchain-core
langchain-community
chromadb
sentence-transformers

pytest
pytest-asyncio
httpx

ğŸ“œ License

This project was developed for a technical assessment.

ğŸ‘¤ Author

Gustavo Santos
Backend Developer â€” Python | FastAPI
GitHub: https://github.com/gusttavosants
